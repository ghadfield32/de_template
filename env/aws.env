# =============================================================================
# de_template: AWS S3 profile
# =============================================================================
# For AWS S3: no MinIO overlay is started (STORAGE=aws_s3).
# Authentication: prefer IAM roles (ECS task role, EC2 instance profile,
# EKS service account with IRSA) over long-lived access keys.
# See docs/06_secrets_and_auth.md for IAM-first patterns.
# Activate: make env-select ENV=env/aws.env
# =============================================================================

# --- Infra Axes ---
BROKER=kafka             # kafka or redpanda — both work with S3
CATALOG=hadoop           # hadoop | rest
STORAGE=aws_s3           # no storage.minio.yml overlay is loaded
MODE=batch

# --- Topic ---
TOPIC=taxi.raw_trips
DLQ_TOPIC=taxi.raw_trips.dlq
DLQ_MAX=0

# --- Data Source ---
DATA_PATH=/data/yellow_tripdata_2024-01.parquet
MAX_EVENTS=0

# --- AWS S3 — replace with your actual bucket ---
WAREHOUSE=s3a://YOUR-BUCKET/warehouse/
S3_ENDPOINT=https://s3.amazonaws.com
S3_USE_SSL=true
S3_PATH_STYLE=false

# --- DuckDB httpfs (NO http:// prefix) ---
DUCKDB_S3_ENDPOINT=s3.amazonaws.com
DUCKDB_S3_USE_SSL=true

# --- Credentials ---
# For EC2/ECS/EKS with IAM role: leave blank (auto-discovered via DefaultAWSCredentialsProviderChain)
# For CI/CD or local dev: inject via environment or AWS Secrets Manager
# Never commit real credentials to git
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1

# --- Project ---
PROJECT=de_pipeline
