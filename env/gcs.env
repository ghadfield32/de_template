# =============================================================================
# de_template: Google Cloud Storage (GCS) profile
# =============================================================================
# GCS via S3-compatibility API using HMAC keys.
# Prefer Workload Identity (GKE) or ADC over HMAC keys for production.
# See docs/06_secrets_and_auth.md for GCS authentication patterns.
# Activate: make env-select ENV=env/gcs.env
# =============================================================================

# --- Infra Axes ---
BROKER=kafka
CATALOG=hadoop
STORAGE=gcs              # no storage.minio.yml overlay is loaded
MODE=batch               # Flink pipeline mode: batch | streaming_bronze

# --- Topic ---
TOPIC=taxi.raw_trips
DLQ_TOPIC=taxi.raw_trips.dlq
DLQ_MAX=0
TOPIC_RETENTION_MS=259200000   # 3 days
DLQ_RETENTION_MS=604800000     # 7 days

# --- Data Source ---
DATA_PATH=/data/yellow_tripdata_2024-01.parquet
MAX_EVENTS=0
GENERATOR_MODE=burst     # Generator send mode: burst | realtime | batch
RATE_LIMIT=0
BATCH_SIZE=1000
BATCH_DELAY=1.0
ALLOW_EMPTY=false        # true only when empty Bronze/Silver outputs are expected
DATASET_NAME=taxi         # expected dataset tag for run_metrics validation
RUN_METRICS_MAX_AGE_MINUTES=120
ALLOW_STALE_RUN_METRICS=false
REQUIRE_RUN_METRICS=true
VALIDATE_SCHEMA=false
SCHEMA_PATH=/schemas/taxi_trip.json
KEY_FIELD=PULocationID

# --- Iceberg table contract ---
BRONZE_TABLE=bronze.raw_trips
SILVER_TABLE=silver.cleaned_trips

# --- Validation thresholds/timeouts ---
BRONZE_COMPLETENESS_RATIO=0.95
WAIT_FOR_SILVER_MIN_ROWS=1
WAIT_FOR_SILVER_TIMEOUT_SECONDS=90
WAIT_FOR_SILVER_POLL_SECONDS=5
HEALTH_HTTP_TIMEOUT_SECONDS=5
HEALTH_DOCKER_TIMEOUT_SECONDS=15
ICEBERG_QUERY_TIMEOUT_SECONDS=90
ICEBERG_METADATA_TIMEOUT_SECONDS=30
DLQ_READ_TIMEOUT_SECONDS=10
DBT_TEST_TIMEOUT_SECONDS=300

# --- GCS S3-compatibility endpoint ---
WAREHOUSE=s3a://YOUR-BUCKET/warehouse/
S3_ENDPOINT=https://storage.googleapis.com
S3_USE_SSL=true
S3_PATH_STYLE=false

# --- DuckDB httpfs (NO http:// prefix) ---
DUCKDB_S3_ENDPOINT=storage.googleapis.com
DUCKDB_S3_USE_SSL=true
DUCKDB_UNSAFE_ENABLE_VERSION_GUESSING=true

# --- GCS HMAC keys (Cloud Console → Storage → Settings → Interoperability) ---
# For GKE + Workload Identity: leave blank; configure k8s service account binding
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=auto

# --- Project ---
PROJECT=de_pipeline
