# =============================================================================
# de_template: Azure Blob Storage (ADLS Gen2) profile
# =============================================================================
# Azure Blob Storage via S3-compatibility layer (requires enabling it on the
# storage account). For production: use Managed Identity + Azure Key Vault.
# See docs/06_secrets_and_auth.md for Azure authentication patterns.
# NOTE: Native abfs:// support for Iceberg requires additional Hadoop Azure jars.
# The S3-compat approach shown here is simpler for initial setup.
# Activate: make env-select ENV=env/azure.env
# =============================================================================

# --- Infra Axes ---
BROKER=kafka
CATALOG=hadoop
STORAGE=azure            # no storage.minio.yml overlay is loaded
MODE=batch

# --- Topic ---
TOPIC=taxi.raw_trips
DLQ_TOPIC=taxi.raw_trips.dlq
DLQ_MAX=0

# --- Data Source ---
DATA_PATH=/data/yellow_tripdata_2024-01.parquet
MAX_EVENTS=0

# --- Azure Blob S3-compatibility endpoint (account-specific) ---
WAREHOUSE=s3a://YOUR-CONTAINER/warehouse/
S3_ENDPOINT=https://YOUR-ACCOUNT.blob.core.windows.net
S3_USE_SSL=true
S3_PATH_STYLE=false

# --- DuckDB httpfs (NO http:// prefix) ---
DUCKDB_S3_ENDPOINT=YOUR-ACCOUNT.blob.core.windows.net
DUCKDB_S3_USE_SSL=true

# --- Storage account key (prefer Managed Identity for Azure workloads) ---
# For Managed Identity: leave blank and configure MSI on the VM/container
AWS_ACCESS_KEY_ID=YOUR-ACCOUNT-NAME
AWS_SECRET_ACCESS_KEY=YOUR-STORAGE-KEY
AWS_REGION=eastus

# --- Project ---
PROJECT=de_pipeline
