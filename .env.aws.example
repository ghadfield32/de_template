# =============================================================================
# de_template: AWS S3 Configuration Example
# =============================================================================
# For AWS S3: no storage overlay is needed (MinIO is not started).
# Authentication: prefer IAM roles (ECS task role, EC2 instance profile, EKS
# service account with IRSA) over long-lived access keys.
# See docs/06_secrets_and_auth.md for IAM-first patterns.
# =============================================================================

BROKER=kafka             # kafka or redpanda — both work with S3
CATALOG=hadoop           # hadoop | rest
STORAGE=aws_s3           # <-- use this; no storage.minio.yml overlay is loaded
MODE=batch

TOPIC=taxi.raw_trips
DLQ_TOPIC=taxi.raw_trips.dlq
DLQ_MAX=0

DATA_PATH=/data/yellow_tripdata_2024-01.parquet
MAX_EVENTS=0

# AWS S3 — replace with your actual bucket
WAREHOUSE=s3a://YOUR-BUCKET/warehouse/
S3_ENDPOINT=https://s3.amazonaws.com
S3_USE_SSL=true
S3_PATH_STYLE=false

DUCKDB_S3_ENDPOINT=s3.amazonaws.com
DUCKDB_S3_USE_SSL=true

# Credentials:
# - For EC2/ECS/EKS with IAM role attached: leave these blank (auto-discovered)
# - For CI/CD or local dev: inject via environment or AWS Secrets Manager
# - Never commit real credentials to git
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1

PROJECT=de_pipeline
